{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-YJHuvFCi4E",
        "outputId": "090cf7d1-a34a-406c-e77b-b9df12c6744f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qOxJ_O0Ci4K"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "thought_dictionary = {\n",
        "    \"Time_of_Thought\": {\n",
        "        \"Morning\": \"6:00-12:00\",\n",
        "        \"Afternoon\": \"12:00-18:00\",\n",
        "        \"Evening\": \"18:00-24:00\",\n",
        "        \"Night\": \"24:00-6:00\"\n",
        "    },\n",
        "    \"Emotional_Tone\": {\n",
        "        \"Joy\": [\"Calm Happiness\", \"Excitement\", \"Contentment\", \"Elation\"],\n",
        "        \"Sadness\": [\"Melancholy\", \"Grief\", \"Loneliness\", \"Regret\"],\n",
        "        \"Anger\": [\"Frustration\", \"Annoyance\", \"Irritation\", \"Rage\"],\n",
        "        \"Fear\": [\"Anxiety\", \"Worry\", \"Terror\", \"Apprehension\"],\n",
        "        \"Surprise\": [\"Curiosity\", \"Amazement\", \"Shock\", \"Startlement\"],\n",
        "        \"Disgust\": [\"Repulsion\", \"Aversion\", \"Contempt\", \"Annoyance\"]\n",
        "    },\n",
        "    \"Cognitive_Load\": {\n",
        "        \"Low\": \"Simple observation, little mental effort\",\n",
        "        \"Moderate\": \"Requires some mental processing\",\n",
        "        \"High\": \"Requires deep thought or complex problem-solving\",\n",
        "        \"Very_High\": \"Highly complex or intense thinking, abstract or multi-layered concepts\"\n",
        "    },\n",
        "    \"Topic_Content_Type\": {\n",
        "        \"Personal\": [\"Self-reflection\", \"Health\", \"Hobbies\", \"Goals\"],\n",
        "        \"Work\": [\"Tasks\", \"Projects\", \"Deadlines\", \"Colleagues\"],\n",
        "        \"Relationships\": [\"Family\", \"Friends\", \"Romantic partner\", \"Social circle\"],\n",
        "        \"Future\": [\"Career plans\", \"Life goals\", \"Financial planning\", \"Aspirations\"],\n",
        "        \"Past\": [\"Memories\", \"Lessons learned\", \"Regrets\", \"Nostalgia\"],\n",
        "        \"General\": [\"Observations\", \"Daily routines\", \"Neutral thoughts\"]\n",
        "    },\n",
        "    \"Degree_of_Focus\": {\n",
        "        \"Focused\": \"Single topic, uninterrupted\",\n",
        "        \"Multi-tasking\": \"Switching between topics or thoughts\",\n",
        "        \"Distracted\": \"Easily diverted, fragmented thoughts\",\n",
        "        \"Scattered\": \"Unclear or jumbled thoughts, unfocused\"\n",
        "    },\n",
        "    \"Actionability\": {\n",
        "        \"Proactive\": [\"Planning\", \"Goal setting\", \"Problem-solving\"],\n",
        "        \"Reactive\": [\"Responding to events or thoughts\", \"Reactions to stimuli\"],\n",
        "        \"Observational\": \"General observation, no action involved\"\n",
        "    },\n",
        "    \"Clarity\": {\n",
        "        \"Clear\": \"Concrete and well-defined\",\n",
        "        \"Vague\": \"Ambiguous, lacking definition\",\n",
        "        \"Abstract\": \"Conceptual, not tied to tangible events\",\n",
        "        \"Fragmented\": \"Incomplete or scattered\"\n",
        "    },\n",
        "    \"Urgency\": {\n",
        "        \"Low\": \"No immediate action needed\",\n",
        "        \"Moderate\": \"Attention needed soon\",\n",
        "        \"High\": \"Requires immediate consideration\",\n",
        "        \"Critical\": \"Demands urgent response\"\n",
        "    },\n",
        "    \"Frequency\": {\n",
        "        \"One-time\": \"Unique thought or occurrence\",\n",
        "        \"Occasional\": \"Happens sporadically\",\n",
        "        \"Frequent\": \"Occurs regularly\",\n",
        "        \"Persistent\": \"Ongoing or recurring thought throughout the day\"\n",
        "    },\n",
        "    \"Impact_Level\": {\n",
        "        \"Low\": \"Minimal effect on mood or plans\",\n",
        "        \"Moderate\": \"Noticeable but manageable\",\n",
        "        \"High\": \"Significant effect, lingering impact\",\n",
        "        \"Very_High\": \"Strong influence on mood, decisions, or actions\"\n",
        "    },\n",
        "    \"Duration\": {\n",
        "        \"Brief\": \"Less than 5 minutes\",\n",
        "        \"Short\": \"5-15 minutes\",\n",
        "        \"Medium\": \"15-30 minutes\",\n",
        "        \"Long\": \"More than 30 minutes\",\n",
        "        \"Ongoing\": \"Recurring throughout the day\"\n",
        "    },\n",
        "    \"Relation_to_Past_Future\": {\n",
        "        \"Past\": [\"Reflection on past events\", \"Reminiscing\", \"Learning from past\"],\n",
        "        \"Present\": \"In-the-moment awareness or reflection\",\n",
        "        \"Future\": [\"Planning\", \"Anticipating\", \"Goal setting\"]\n",
        "    },\n",
        "    \"Sensory_Associations\": {\n",
        "        \"Visual\": [\"Mental imagery\", \"Detailed scenes\", \"Colors\"],\n",
        "        \"Auditory\": [\"Sounds\", \"Voices\", \"Music\"],\n",
        "        \"Tactile\": [\"Sensory feelings\", \"Textures\"],\n",
        "        \"None\": \"No sensory elements present\"\n",
        "    },\n",
        "    \"Self_Other_Focused\": {\n",
        "        \"Self\": [\"Self-improvement\", \"Personal goals\", \"Self-reflection\"],\n",
        "        \"Other\": [\"Thoughts about others' actions\", \"Social interactions\", \"External events\"],\n",
        "        \"Environment\": [\"Observations about surroundings\", \"Environmental stimuli\"]\n",
        "    },\n",
        "    \"Positivity_Negativity\": {\n",
        "        \"Positive\": [\"Optimistic\", \"Hopeful\", \"Grateful\", \"Content\"],\n",
        "        \"Neutral\": [\"Observational\", \"Non-judgmental\", \"Objective\"],\n",
        "        \"Negative\": [\"Pessimistic\", \"Critical\", \"Discontent\", \"Regretful\"]\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMqyhbbmCi4N"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"What a beautiful morning! I feel so grateful to have this peaceful moment before the day starts.\": {\n",
        "        \"Time_of_Thought\": \"Morning\",\n",
        "        \"Emotional_Tone\": \"Joy\",\n",
        "        \"Cognitive_Load\": \"Low\",\n",
        "        \"Topic_Content_Type\": \"Personal\",\n",
        "        \"Degree_of_Focus\": \"Focused\",\n",
        "        \"Actionability\": \"Observational\",\n",
        "        \"Clarity\": \"Clear\",\n",
        "        \"Urgency\": \"Low\",\n",
        "        \"Frequency\": \"One-time\",\n",
        "        \"Impact_Level\": \"Low\",\n",
        "        \"Duration\": \"Brief\",\n",
        "        \"Relation_to_Past_Future\": \"Present\",\n",
        "        \"Sensory_Associations\": \"Visual\",\n",
        "        \"Self_Other_Focused\": \"Self\",\n",
        "        \"Positivity_Negativity\": \"Positive\",\n",
        "    },\n",
        "\n",
        "    \"So much stuff to do today.\": {\n",
        "        \"Time_of_Thought\": \"Morning\",\n",
        "        \"Emotional_Tone\": \"Neutral\",\n",
        "        \"Cognitive_Load\": \"Moderate\",\n",
        "        \"Topic_Content_Type\": \"Work\",\n",
        "        \"Degree_of_Focus\": \"Multi-tasking\",\n",
        "        \"Actionability\": \"Proactive\",\n",
        "        \"Clarity\": \"Clear\",\n",
        "        \"Urgency\": \"Moderate\",\n",
        "        \"Frequency\": \"Frequent\",\n",
        "        \"Impact_Level\": \"Moderate\",\n",
        "        \"Duration\": \"Short\",\n",
        "        \"Relation_to_Past_Future\": \"Future\",\n",
        "        \"Sensory_Associations\": \"None\",\n",
        "        \"Self_Other_Focused\": \"Self\",\n",
        "        \"Positivity_Negativity\": \"Neutral\",\n",
        "    },\n",
        "\n",
        "    \"I really miss those old days with my friends.\": {\n",
        "        \"Time_of_Thought\": \"Evening\",\n",
        "        \"Emotional_Tone\": \"Sadness\",\n",
        "        \"Cognitive_Load\": \"High\",\n",
        "        \"Topic_Content_Type\": \"Relationships\",\n",
        "        \"Degree_of_Focus\": \"Focused\",\n",
        "        \"Actionability\": \"Observational\",\n",
        "        \"Clarity\": \"Vague\",\n",
        "        \"Urgency\": \"Low\",\n",
        "        \"Frequency\": \"Occasional\",\n",
        "        \"Impact_Level\": \"High\",\n",
        "        \"Duration\": \"Medium\",\n",
        "        \"Relation_to_Past_Future\": \"Past\",\n",
        "        \"Sensory_Associations\": \"Visual\",\n",
        "        \"Self_Other_Focused\": \"Other\",\n",
        "        \"Positivity_Negativity\": \"Negative\",\n",
        "    },\n",
        "\n",
        "    \"I wonder what the next steps are for my career growth.\": {\n",
        "        \"Time_of_Thought\": \"Afternoon\",\n",
        "        \"Emotional_Tone\": \"Curiosity\",\n",
        "        \"Cognitive_Load\": \"Moderate\",\n",
        "        \"Topic_Content_Type\": \"Future\",\n",
        "        \"Degree_of_Focus\": \"Focused\",\n",
        "        \"Actionability\": \"Proactive\",\n",
        "        \"Clarity\": \"Abstract\",\n",
        "        \"Urgency\": \"Moderate\",\n",
        "        \"Frequency\": \"Frequent\",\n",
        "        \"Impact_Level\": \"Moderate\",\n",
        "        \"Duration\": \"Short\",\n",
        "        \"Relation_to_Past_Future\": \"Future\",\n",
        "        \"Sensory_Associations\": \"None\",\n",
        "        \"Self_Other_Focused\": \"Self\",\n",
        "        \"Positivity_Negativity\": \"Neutral\",\n",
        "    },\n",
        "\n",
        "    \"That movie was really interesting!\": {\n",
        "        \"Time_of_Thought\": \"Night\",\n",
        "        \"Emotional_Tone\": \"Surprise\",\n",
        "        \"Cognitive_Load\": \"Low\",\n",
        "        \"Topic_Content_Type\": \"General\",\n",
        "        \"Degree_of_Focus\": \"Focused\",\n",
        "        \"Actionability\": \"Observational\",\n",
        "        \"Clarity\": \"Clear\",\n",
        "        \"Urgency\": \"Low\",\n",
        "        \"Frequency\": \"One-time\",\n",
        "        \"Impact_Level\": \"Low\",\n",
        "        \"Duration\": \"Brief\",\n",
        "        \"Relation_to_Past_Future\": \"Present\",\n",
        "        \"Sensory_Associations\": \"Visual\",\n",
        "        \"Self_Other_Focused\": \"Environment\",\n",
        "        \"Positivity_Negativity\": \"Positive\",\n",
        "    },\n",
        "\n",
        "    \"I need to finish this report by tomorrow!\": {\n",
        "        \"Time_of_Thought\": \"Afternoon\",\n",
        "        \"Emotional_Tone\": \"Stress\",\n",
        "        \"Cognitive_Load\": \"High\",\n",
        "        \"Topic_Content_Type\": \"Work\",\n",
        "        \"Degree_of_Focus\": \"Focused\",\n",
        "        \"Actionability\": \"Proactive\",\n",
        "        \"Clarity\": \"Clear\",\n",
        "        \"Urgency\": \"High\",\n",
        "        \"Frequency\": \"Frequent\",\n",
        "        \"Impact_Level\": \"High\",\n",
        "        \"Duration\": \"Medium\",\n",
        "        \"Relation_to_Past_Future\": \"Future\",\n",
        "        \"Sensory_Associations\": \"None\",\n",
        "        \"Self_Other_Focused\": \"Self\",\n",
        "        \"Positivity_Negativity\": \"Negative\",\n",
        "    },\n",
        "\n",
        "    \"It's great to see my efforts being recognized.\": {\n",
        "        \"Time_of_Thought\": \"Evening\",\n",
        "        \"Emotional_Tone\": \"Joy\",\n",
        "        \"Cognitive_Load\": \"Moderate\",\n",
        "        \"Topic_Content_Type\": \"Work\",\n",
        "        \"Degree_of_Focus\": \"Focused\",\n",
        "        \"Actionability\": \"Observational\",\n",
        "        \"Clarity\": \"Clear\",\n",
        "        \"Urgency\": \"Low\",\n",
        "        \"Frequency\": \"Occasional\",\n",
        "        \"Impact_Level\": \"Moderate\",\n",
        "        \"Duration\": \"Short\",\n",
        "        \"Relation_to_Past_Future\": \"Present\",\n",
        "        \"Sensory_Associations\": \"None\",\n",
        "        \"Self_Other_Focused\": \"Self\",\n",
        "        \"Positivity_Negativity\": \"Positive\",\n",
        "    }\n",
        "}\n",
        "\n",
        "# Expanded sequence of thought texts for input into your model\n",
        "seq = list(data.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOd27mKICi4O",
        "outputId": "bae7e062-e64a-4e20-e329-91995752bfdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Encoded Data as List:\n",
            "[array([0.        , 0.2759143 , 0.2759143 , 0.        , 0.        ,\n",
            "       0.        , 0.2759143 , 0.        , 0.        , 0.        ,\n",
            "       0.2759143 , 0.        , 0.        , 0.        , 0.2759143 ,\n",
            "       0.        , 0.        , 0.2759143 , 0.        , 0.        ,\n",
            "       0.        , 0.2759143 , 0.2759143 , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.2759143 ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.22903257,\n",
            "       0.2759143 , 0.        , 0.        , 0.        , 0.22903257,\n",
            "       0.22903257, 0.        , 0.16996856, 0.        , 0.        ,\n",
            "       0.        , 0.22903257, 0.        , 0.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       1.        , 1.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       1.        , 0.        , 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.44418032, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.44418032,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.36870781,\n",
            "       0.        , 0.        , 0.44418032, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.2736237 , 0.44418032, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
            "       2.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 2.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 2.        , 2.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.37287289, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.37287289, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.37287289, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.26456446, 0.        , 0.        , 0.37287289, 0.        ,\n",
            "       0.30951652, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.37287289, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.37287289, 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       3.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       1.        , 0.        , 0.        , 3.        , 3.        ,\n",
            "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 1.        ]), array([0.33554935, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.33554935, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.33554935, 0.        , 0.        ,\n",
            "       0.        , 0.33554935, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.2380823 , 0.        , 0.33554935, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.33554935, 0.        , 0.        , 0.27853478,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.27853478, 0.        , 0.33554935, 0.        ,\n",
            "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       2.        , 0.        , 0.        , 0.        , 1.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 2.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 2.        , 2.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.46180424, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.46180424, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.38333718, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.46180424, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.46180424, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
            "       1.        , 0.        , 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.40593689,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.40593689, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.40593689, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.40593689, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.33696248, 0.        , 0.250065  , 0.        , 0.40593689,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       3.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 3.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 3.        , 3.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 1.        ]), array([0.        , 0.        , 0.        , 0.38116575, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.38116575,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.38116575, 0.        , 0.        , 0.        , 0.38116575,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.2704485 , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.38116575, 0.        , 0.38116575, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.2348055 , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 0.        , 1.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       2.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
            "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
            "       1.        , 0.        , 0.        , 2.        , 2.        ,\n",
            "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
            "       1.        , 0.        , 0.        ])]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Dictionary for ordinal encodings\n",
        "ordinal_encodings = {\n",
        "    \"Cognitive_Load\": {\"Low\": 1, \"Moderate\": 2, \"High\": 3, \"Very_High\": 4},\n",
        "    \"Urgency\": {\"Low\": 1, \"Moderate\": 2, \"High\": 3, \"Critical\": 4},\n",
        "    \"Impact_Level\": {\"Low\": 1, \"Moderate\": 2, \"High\": 3, \"Very_High\": 4},\n",
        "    \"Duration\": {\"Brief\": 1, \"Short\": 2, \"Medium\": 3, \"Long\": 4, \"Ongoing\": 5}\n",
        "}\n",
        "\n",
        "# Sample thought dictionary for one-hot encoding\n",
        "thought_dictionary = {\n",
        "    \"Time_of_Thought\": [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"],\n",
        "    \"Emotional_Tone\": [\"Joy\", \"Sadness\", \"Anger\", \"Fear\", \"Surprise\", \"Disgust\", \"Neutral\"],\n",
        "    \"Topic_Content_Type\": [\"Personal\", \"Work\", \"Relationships\", \"Future\", \"Past\", \"General\"],\n",
        "    \"Degree_of_Focus\": [\"Focused\", \"Multi-tasking\", \"Distracted\", \"Scattered\"],\n",
        "    \"Actionability\": [\"Proactive\", \"Reactive\", \"Observational\"],\n",
        "    \"Clarity\": [\"Clear\", \"Vague\", \"Abstract\", \"Fragmented\"],\n",
        "    \"Frequency\": [\"One-time\", \"Occasional\", \"Frequent\", \"Persistent\"],\n",
        "    \"Relation_to_Past_Future\": [\"Past\", \"Present\", \"Future\"],\n",
        "    \"Sensory_Associations\": [\"Visual\", \"Auditory\", \"Tactile\", \"None\"],\n",
        "    \"Self_Other_Focused\": [\"Self\", \"Other\", \"Environment\"],\n",
        "    \"Positivity_Negativity\": [\"Positive\", \"Neutral\", \"Negative\"]\n",
        "}\n",
        "\n",
        "# Encoding function for structured thought data\n",
        "def one_hot_encode(value, categories):\n",
        "    return [1 if category == value else 0 for category in categories]\n",
        "\n",
        "def encode_thought(thought, thought_dict, ordinal_dict):\n",
        "    encoded_thought = []\n",
        "    for feature, value in thought.items():\n",
        "        if feature in ordinal_dict:\n",
        "            encoded_thought.append(ordinal_dict[feature].get(value, 0))\n",
        "        else:\n",
        "            categories = thought_dict[feature]\n",
        "            encoded_thought.extend(one_hot_encode(value, categories))\n",
        "    return encoded_thought\n",
        "\n",
        "# Text embedding using TF-IDF (other embeddings can be used as well)\n",
        "texts = list(data.keys())\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "# Generate list of encoded vectors for each thought\n",
        "final_encoded_data = []\n",
        "for idx, (text, thought) in enumerate(data.items()):\n",
        "    # Encode structured thought data\n",
        "    encoded_thought = encode_thought(thought, thought_dictionary, ordinal_encodings)\n",
        "\n",
        "    # Get the text embedding\n",
        "    text_embedding = tfidf_matrix[idx]\n",
        "\n",
        "    # Combine text embedding and structured data encoding\n",
        "    combined_encoding = np.concatenate([text_embedding, encoded_thought])\n",
        "    final_encoded_data.append(combined_encoding)\n",
        "\n",
        "# final_encoded_data will now have each thought in its respective position\n",
        "print(\"Final Encoded Data as List:\")\n",
        "print(final_encoded_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgOKSxNzCi4P",
        "outputId": "795c5556-ea66-4fed-ed7e-fadbbdbbbe9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Text Embedding (TF-IDF or similar): [0.         0.2759143  0.2759143  0.         0.         0.\n",
            " 0.2759143  0.         0.         0.         0.2759143  0.\n",
            " 0.         0.         0.2759143  0.         0.         0.2759143\n",
            " 0.         0.         0.         0.2759143  0.2759143  0.\n",
            " 0.         0.         0.         0.         0.         0.2759143\n",
            " 0.         0.         0.         0.         0.22903257 0.2759143\n",
            " 0.         0.         0.         0.22903257 0.22903257 0.\n",
            " 0.16996856 0.         0.         0.         0.22903257 0.\n",
            " 0.        ]\n",
            "Decoded Structured Thought Data:\n",
            "Time_of_Thought: Morning\n",
            "Emotional_Tone: Joy\n",
            "Topic_Content_Type: Personal\n",
            "Degree_of_Focus: Multi-tasking\n",
            "Actionability: Proactive\n",
            "Clarity: Clear\n",
            "Frequency: Occasional\n",
            "Relation_to_Past_Future: Future\n",
            "Sensory_Associations: Visual\n",
            "Self_Other_Focused: Self\n",
            "Positivity_Negativity: Neutral\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reverse mappings for ordinal encodings\n",
        "ordinal_decodings = {\n",
        "    \"Cognitive_Load\": {1: \"Low\", 2: \"Moderate\", 3: \"High\", 4: \"Very_High\"},\n",
        "    \"Urgency\": {1: \"Low\", 2: \"Moderate\", 3: \"High\", 4: \"Critical\"},\n",
        "    \"Impact_Level\": {1: \"Low\", 2: \"Moderate\", 3: \"High\", 4: \"Very_High\"},\n",
        "    \"Duration\": {1: \"Brief\", 2: \"Short\", 3: \"Medium\", 4: \"Long\", 5: \"Ongoing\"}\n",
        "}\n",
        "\n",
        "# Main categories without nested meanings, to align with one-hot encoding\n",
        "thought_dictionary = {\n",
        "    \"Time_of_Thought\": [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"],\n",
        "    \"Emotional_Tone\": [\"Joy\", \"Sadness\", \"Anger\", \"Fear\", \"Surprise\", \"Disgust\", \"Neutral\"],\n",
        "    \"Topic_Content_Type\": [\"Personal\", \"Work\", \"Relationships\", \"Future\", \"Past\", \"General\"],\n",
        "    \"Degree_of_Focus\": [\"Focused\", \"Multi-tasking\", \"Distracted\", \"Scattered\"],\n",
        "    \"Actionability\": [\"Proactive\", \"Reactive\", \"Observational\"],\n",
        "    \"Clarity\": [\"Clear\", \"Vague\", \"Abstract\", \"Fragmented\"],\n",
        "    \"Frequency\": [\"One-time\", \"Occasional\", \"Frequent\", \"Persistent\"],\n",
        "    \"Relation_to_Past_Future\": [\"Past\", \"Present\", \"Future\"],\n",
        "    \"Sensory_Associations\": [\"Visual\", \"Auditory\", \"Tactile\", \"None\"],\n",
        "    \"Self_Other_Focused\": [\"Self\", \"Other\", \"Environment\"],\n",
        "    \"Positivity_Negativity\": [\"Positive\", \"Neutral\", \"Negative\"]\n",
        "}\n",
        "\n",
        "# Decode function for structured data\n",
        "def decode_one_hot(encoded, categories):\n",
        "    \"\"\"Decode a one-hot encoded list back to its original category.\"\"\"\n",
        "    index = np.argmax(encoded)\n",
        "    return categories[index]\n",
        "\n",
        "def decode_thought(encoded_vector, text_vector_size, thought_dict, ordinal_dict):\n",
        "    # Ensure text_vector_size does not exceed the total encoded vector length\n",
        "    if text_vector_size > len(encoded_vector):\n",
        "        raise ValueError(\"text_vector_size is larger than the encoded vector length.\")\n",
        "\n",
        "    # Split `encoded_vector` into text and structured encoding parts\n",
        "    text_embedding = encoded_vector[:text_vector_size]\n",
        "    thought_encoding = encoded_vector[text_vector_size:]\n",
        "\n",
        "    decoded_thought = {}\n",
        "    index = 0\n",
        "\n",
        "    # Decode each feature based on its encoding type (one-hot or ordinal)\n",
        "    for feature, categories in thought_dict.items():\n",
        "        if feature in ordinal_dict:\n",
        "            # Ordinal feature decoding\n",
        "            ordinal_value = int(thought_encoding[index])\n",
        "            decoded_thought[feature] = ordinal_dict[feature].get(ordinal_value, \"Unknown\")\n",
        "            index += 1\n",
        "        else:\n",
        "            # One-hot feature decoding\n",
        "            one_hot_length = len(categories)\n",
        "            one_hot_encoded = thought_encoding[index:index + one_hot_length]\n",
        "            decoded_value = decode_one_hot(one_hot_encoded, categories)\n",
        "            decoded_thought[feature] = decoded_value\n",
        "            index += one_hot_length\n",
        "\n",
        "    # Return decoded text embedding and thought structure\n",
        "    return text_embedding, decoded_thought\n",
        "\n",
        "# Example encoded vector (from final_encoded_data list)\n",
        "example_encoded_vector = final_encoded_data[0]  # Replace with actual encoded vector\n",
        "text_vector_size = tfidf_matrix.shape[1]  # Ensure correct text embedding size\n",
        "\n",
        "# Decode the example vector\n",
        "text_embedding, decoded_thought = decode_thought(example_encoded_vector, text_vector_size, thought_dictionary, ordinal_decodings)\n",
        "\n",
        "# Output decoded thought\n",
        "print(\"Decoded Text Embedding (TF-IDF or similar):\", text_embedding)\n",
        "print(\"Decoded Structured Thought Data:\")\n",
        "for key, value in decoded_thought.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvj2JnyUCi4Q",
        "outputId": "9a9bcb49-f372-4030-8910-00da712352a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of sample_encoded_data: (7, 98)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the list of arrays into a single 2D numpy array\n",
        "sample_encoded_data = np.vstack(final_encoded_data)\n",
        "\n",
        "# Check the shape to verify conversion\n",
        "print(\"Shape of sample_encoded_data:\", sample_encoded_data.shape)  # Should be (num_samples, feature_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u_b8oWyCi4Q",
        "outputId": "a19e7746-4421-409b-b380-e905e70d550c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (5, 2, 98)\n",
            "Shape of y: (5, 98)\n"
          ]
        }
      ],
      "source": [
        "# Define sequence length\n",
        "sequence_length = 2  # Number of previous thoughts to use as context\n",
        "\n",
        "X, y = [], []\n",
        "for i in range(len(sample_encoded_data) - sequence_length):\n",
        "    X.append(sample_encoded_data[i:i + sequence_length])  # Sequence of encoded thoughts\n",
        "    y.append(sample_encoded_data[i + sequence_length])    # Next thought as target\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Verify shapes\n",
        "print(\"Shape of X:\", X.shape)  # Expected: (number of samples, sequence_length, feature_count)\n",
        "print(\"Shape of y:\", y.shape)  # Expected: (number of samples, feature_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ5MXf7SCi4R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f08f40e4-160b-4ffa-839f-270ba9216a0c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m41,728\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)                  │           \u001b[38;5;34m3,234\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,728</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,234</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,378\u001b[0m (224.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,378</span> (224.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,378\u001b[0m (224.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,378</span> (224.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 0.3206\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3174\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3128\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3097\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3062\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3051\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3014\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2978\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2960\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2913\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2924\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2854\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2797\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2760\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2784\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2719\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2716\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2639\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2584\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2537\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2507\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2488\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2447\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2308\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2183\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2131\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2161\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2123\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1980\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1832\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1862\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1887\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1792\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1755\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1795\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1589\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1780\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1527\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1473\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1610\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1414\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1463\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1433\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1465\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1371\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1376\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1461\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1305\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1191\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fdb7fd2fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the LSTM model\n",
        "def build_predictive_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(32, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(sample_encoded_data.shape[1], activation='linear'))  # Output layer matches feature count\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = build_predictive_model(input_shape=(X.shape[1], X.shape[2]))\n",
        "\n",
        "# Train the model with multi-threading enabled\n",
        "model.summary()\n",
        "model.fit(X, y, epochs=50, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM7BEMB4Ci4S",
        "outputId": "e0041321-f7d4-4cc8-f78c-880171fe0738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
            "Predicted Encoded Next Thought: [[ 6.44404069e-02  3.51678282e-02  3.76517139e-02  4.37946152e-03\n",
            "   5.82280681e-02  7.67874420e-02 -9.60331038e-03  7.78746456e-02\n",
            "   1.47725604e-02  8.63714367e-02 -2.32185349e-02  2.23111622e-02\n",
            "   5.50088063e-02  4.46094647e-02  3.37344594e-02  1.52749717e-01\n",
            "   3.15130651e-02 -2.62894370e-02  1.21015377e-01  7.37749785e-02\n",
            "   6.86651617e-02  2.66708136e-02 -2.85939258e-02  1.04724150e-02\n",
            "  -2.27217209e-02  1.38472557e-01  8.20084959e-02  4.91381288e-02\n",
            "   3.03729102e-02  2.03371216e-02  1.59127206e-01  4.06099409e-02\n",
            "   5.10109216e-02  7.29081556e-02 -8.38432461e-04  3.99909317e-02\n",
            "   3.07783373e-02  1.47202695e-02  1.24088973e-01  4.30223942e-02\n",
            "   6.67545870e-02  8.77914429e-02  4.60117757e-02  5.35993744e-03\n",
            "   8.33976865e-02  8.90125781e-02  2.46552434e-02  8.78134668e-02\n",
            "   9.52359289e-02  3.70107144e-02  4.33775008e-01  4.21589553e-01\n",
            "   2.26256624e-01  1.95116505e-01  2.05878377e-01  6.09067567e-02\n",
            "   1.58249829e-02  1.02492787e-01 -2.24250406e-02  1.97392367e-02\n",
            "   1.48338902e+00  7.20009021e-03  4.92525399e-01  2.03561291e-01\n",
            "   1.57784760e-01 -4.67291810e-02  2.47419640e-01  5.92187047e-01\n",
            "   4.01774794e-03  3.15666050e-02  4.92821187e-02  4.11978900e-01\n",
            "   3.69090959e-02  7.26635456e-01  6.94301784e-01  1.63829103e-01\n",
            "   2.22099930e-01 -2.22497322e-02  1.31359577e+00  2.66253233e-01\n",
            "   4.26259995e-01  5.18311620e-01 -3.06426398e-02  1.56366956e+00\n",
            "   2.02042222e+00  2.05900252e-01  3.41294080e-01  4.32282120e-01\n",
            "   4.27730083e-01  2.19982732e-02 -2.19897050e-02  6.39922917e-01\n",
            "   6.64672434e-01  1.46724403e-01  1.98220953e-01  4.87229586e-01\n",
            "   2.04608291e-01  4.79812682e-01]]\n"
          ]
        }
      ],
      "source": [
        "# Example prediction using the last sequence in X\n",
        "new_sequence = np.expand_dims(X[-1], axis=0)  # Shape to (1, sequence_length, feature_count)\n",
        "predicted_next_thought = model.predict(new_sequence)\n",
        "\n",
        "print(\"Predicted Encoded Next Thought:\", predicted_next_thought)\n",
        "predicted_next_thought = predicted_next_thought.reshape(-1)\n",
        "final_encoded_data.append(predicted_next_thought)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2QVuIJPCi4S",
        "outputId": "abb6d60b-1210-4276-bb2e-8a246962327e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Text Embedding (TF-IDF or similar): [ 0.06444041  0.03516783  0.03765171  0.00437946  0.05822807  0.07678744\n",
            " -0.00960331  0.07787465  0.01477256  0.08637144 -0.02321853  0.02231116\n",
            "  0.05500881  0.04460946  0.03373446  0.15274972  0.03151307 -0.02628944\n",
            "  0.12101538  0.07377498  0.06866516  0.02667081 -0.02859393  0.01047242\n",
            " -0.02272172  0.13847256  0.0820085   0.04913813  0.03037291  0.02033712\n",
            "  0.1591272   0.04060994  0.05101092  0.07290816 -0.00083843  0.03999093\n",
            "  0.03077834  0.01472027  0.12408897  0.04302239  0.06675459  0.08779144\n",
            "  0.04601178  0.00535994  0.08339769  0.08901258  0.02465524  0.08781347\n",
            "  0.09523593  0.03701071  0.433775    0.42158955  0.22625662]\n",
            "Decoded Structured Thought Data:\n",
            "Time_of_Thought: Afternoon\n",
            "Emotional_Tone: Fear\n",
            "Topic_Content_Type: Future\n",
            "Degree_of_Focus: Scattered\n",
            "Actionability: Proactive\n",
            "Clarity: Vague\n",
            "Frequency: Persistent\n",
            "Relation_to_Past_Future: Future\n",
            "Sensory_Associations: None\n",
            "Self_Other_Focused: Self\n",
            "Positivity_Negativity: Positive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Select the last encoded thought for decoding\n",
        "example_encoded_vector = final_encoded_data[-1]\n",
        "\n",
        "# Verify the total length of example_encoded_vector\n",
        "total_vector_length = len(example_encoded_vector)\n",
        "\n",
        "# Calculate the length of structured encoding based on thought_dictionary and ordinal_encodings\n",
        "structured_encoding_length = sum(\n",
        "    len(categories) if feature not in ordinal_decodings else 1\n",
        "    for feature, categories in thought_dictionary.items()\n",
        ")\n",
        "\n",
        "# Dynamically calculate text_vector_size\n",
        "text_vector_size = total_vector_length - structured_encoding_length\n",
        "\n",
        "# Check if the calculated text_vector_size is valid\n",
        "if text_vector_size <= 0 or text_vector_size >= total_vector_length:\n",
        "    raise ValueError(\"Calculated text_vector_size is invalid. Please verify the encoding structure.\")\n",
        "\n",
        "# Decode the example vector using the decode_thought function\n",
        "try:\n",
        "    # Decode structured data using decode_thought\n",
        "    text_embedding, decoded_thought = decode_thought(\n",
        "        example_encoded_vector,\n",
        "        text_vector_size,\n",
        "        thought_dictionary,\n",
        "        ordinal_decodings\n",
        "    )\n",
        "\n",
        "    # Output the decoded thought\n",
        "    print(\"Decoded Text Embedding (TF-IDF or similar):\", text_embedding)\n",
        "    print(\"Decoded Structured Thought Data:\")\n",
        "    for key, value in decoded_thought.items():  # Iterate over the dictionary\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error in decoding:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoded_thought)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP00zPwdeu2h",
        "outputId": "48e031a3-638d-471d-b777-172215080c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Time_of_Thought': 'Afternoon', 'Emotional_Tone': 'Fear', 'Topic_Content_Type': 'Future', 'Degree_of_Focus': 'Scattered', 'Actionability': 'Proactive', 'Clarity': 'Vague', 'Frequency': 'Persistent', 'Relation_to_Past_Future': 'Future', 'Sensory_Associations': 'None', 'Self_Other_Focused': 'Self', 'Positivity_Negativity': 'Positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbMBwjnhFrb",
        "outputId": "c28af941-c0bb-43cc-e0f3-4d51dacde4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "czIkeUZthyns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\"\n",
        "\n",
        "client = OpenAI(api_key = api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "\n",
        "\n",
        "Given {decoded_thought}, generate an example thought that addresses each attribute in a coherent way. Return only the generated thought.\n",
        "\n",
        "\n",
        "        \"\"\"}\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=200,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "    )\n",
        "\n",
        "    # Extracting the ticker symbol from the response\n",
        "ans = response.choices[0].message.content\n",
        "print(ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hGtB47HhzY4",
        "outputId": "e665777a-88b7-4f15-9693-c1a7ca96bfd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"I'm feeling a bit scared and anxious about what the future holds for me. My thoughts are all over the place this afternoon, it's hard to focus on one thing. I need to start taking proactive steps to ensure my future is secure, but everything seems so vague and uncertain. These persistent thoughts keep coming back, always about the future, never about the past. There's no particular sensory association, it's all in my head. I need to stop worrying about myself so much and try to stay positive, but it's easier said than done.\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}